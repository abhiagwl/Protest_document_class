{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D,merge, MaxPooling1D, Embedding,Merge,  Dropout\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers.merge import Add,Concatenate,Dot\n",
    "\n",
    "\n",
    "BASE_DIR = ''\n",
    "GLOVE_DIR = '/home/abhinav/data/GLOVE_DATA/glove.6B'\n",
    "TEXT_DATA_DIR = '/home/abhinav/data/full_text'\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NB_WORDS = 50000\n",
    "EMBEDDING_DIM = 100\n",
    "num_words = MAX_NB_WORDS\n",
    "MOD_DIR = \"/home/abhinav/data/sixth_model_alan_filtering/\"\n",
    "\n",
    "\n",
    "print('Loading data...')\n",
    "[x_train, y_train] = pd.read_pickle(MOD_DIR + \"train_data\") \n",
    "\n",
    "[x_test, y_test] = pd.read_pickle(MOD_DIR + \"test_dataset\") \n",
    "\n",
    "print(\"Loading the Embedding matrix\")\n",
    "\n",
    "embedding_matrix = pd.read_pickle(MOD_DIR + \"embedding_matrix\")\n",
    "\n",
    "\n",
    "\n",
    "#some helper functions\n",
    "\n",
    "class Metrics(keras.callbacks.Callback):\n",
    "    def __init__(self,filepath):\n",
    "        self.filepath = filepath\n",
    "        self.best = -np.Inf\n",
    "    def on_epoch_end(self, epoch,batch, logs={}):\n",
    "        predict = self.model.predict(self.validation_data[0],batch_size = 512)\n",
    "        predict = prob_to_label(predict)\n",
    "        targ = self.validation_data[1]\n",
    "        self.f1s=f1(targ, predict)\n",
    "        \"\"\"if self.f1s > self.best:\n",
    "            self.best = self.f1s\n",
    "            print('Epoch %05d: improved f1 to %0.5f,'\n",
    "                                  ' saving model to %s'\n",
    "                                  % (epoch, self.best, self.filepath))\n",
    "            self.model.save(self.filepath,overwrite =True)\"\"\"\n",
    "        print (\"\\nWeighted F1 score found on Validation dataset : \" ,self.f1s)\n",
    "        return\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "def f1(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true = y_true, y_pred = y_pred)\n",
    "ndm = keras.optimizers.Nadam(lr = 0.001)    \n",
    "\n",
    "def prob_to_label(array):\n",
    "    for a in array:\n",
    "        if a[0] > a[1] :\n",
    "            a[0] = 1\n",
    "            a[1] = 0\n",
    "        elif a[0] < a[1]:\n",
    "            a[0] = 0\n",
    "            a[1] = 1\n",
    "        else:\n",
    "            ind = np.random.randint(2)\n",
    "            a[ind]= 1\n",
    "            a[int(1-ind)] = 0\n",
    "    return array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, 1000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)          (None, 1000, 100)     5000000     input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)               (None, 998, 128)      38528       embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)               (None, 997, 128)      51328       embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)               (None, 996, 128)      64128       embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling1D)  (None, 199, 128)      0           conv1d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling1D)  (None, 199, 128)      0           conv1d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D)  (None, 199, 128)      0           conv1d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_5 (Merge)                  (None, 597, 128)      0           max_pooling1d_19[0][0]           \n",
      "                                                                   max_pooling1d_20[0][0]           \n",
      "                                                                   max_pooling1d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)               (None, 593, 128)      82048       merge_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D)  (None, 118, 128)      0           conv1d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)               (None, 114, 128)      82048       max_pooling1d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D)  (None, 3, 128)        0           conv1d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 384)           0           max_pooling1d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 128)           49280       flatten_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 2)             258         dense_10[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 5,367,618\n",
      "Trainable params: 5,367,618\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:25: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Declaring the Model\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n",
    "\n",
    "# applying a more complex convolutional approach\n",
    "convs = []\n",
    "filter_sizes = [3,4,5]\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "for fsz in filter_sizes:\n",
    "    l_conv = Conv1D(filters=128,kernel_size=fsz,activation='relu')(embedded_sequences)\n",
    "    l_pool = MaxPooling1D(5)(l_conv)\n",
    "    convs.append(l_pool)\n",
    "    \n",
    "l_merge = Merge(mode='concat', concat_axis=1)(convs)\n",
    "l_cov1= Conv1D(128, 5, activation='relu')(l_merge)\n",
    "l_pool1 = MaxPooling1D(5)(l_cov1)\n",
    "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n",
    "l_pool2 = MaxPooling1D(30)(l_cov2)\n",
    "l_flat = Flatten()(l_pool2)\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "preds = Dense(2, activation='softmax')(l_dense)\n",
    "\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=ndm,\n",
    "              metrics=['acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_weights = model.get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 9937 samples, validate on 45500 samples\n",
      "Epoch 1/10\n",
      "9856/9937 [============================>.] - ETA: 2s - loss: 0.3704 - acc: 0.8738\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.98901099,  0.        ]), array([ 1.,  0.]), array([ 0.99447514,  0.        ]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 1018s - loss: 0.3697 - acc: 0.8741 - val_loss: 0.1509 - val_acc: 0.9890\n",
      "Epoch 2/10\n",
      "9856/9937 [============================>.] - ETA: 2s - loss: 0.3045 - acc: 0.8849\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.98901099,  0.        ]), array([ 1.,  0.]), array([ 0.99447514,  0.        ]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 1003s - loss: 0.3048 - acc: 0.8848 - val_loss: 0.1997 - val_acc: 0.9890\n",
      "Epoch 3/10\n",
      "6656/9937 [===================>..........] - ETA: 80s - loss: 0.2823 - acc: 0.8867"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-d66e0f902d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0.\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m          callbacks = [metrics])\n\u001b[0m",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.set_weights(initial_weights)\n",
    "print('Train...')\n",
    "metrics = Metrics(MOD_DIR + \"none\")\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          class_weight = {0. : 1, 1. : 1},\n",
    "validation_data=[x_test, y_test],\n",
    "         callbacks = [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 9937 samples, validate on 45500 samples\n",
      "Epoch 1/10\n",
      "9856/9937 [============================>.] - ETA: 2s - loss: 0.6865 - acc: 0.8745\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.98901099,  0.        ]), array([ 1.,  0.]), array([ 0.99447514,  0.        ]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 986s - loss: 0.6846 - acc: 0.8749 - val_loss: 0.2547 - val_acc: 0.9890\n",
      "Epoch 2/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.5969 - acc: 0.8698\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99273463,  0.02355316]), array([ 0.77428889,  0.49      ]), array([ 0.87000924,  0.04494588]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 945s - loss: 0.5980 - acc: 0.8694 - val_loss: 0.4015 - val_acc: 0.7712\n",
      "Epoch 3/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.5178 - acc: 0.8282\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99373683,  0.02375915]), array([ 0.73337778,  0.584     ]), array([ 0.843933  ,  0.04566067]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 944s - loss: 0.5189 - acc: 0.8281 - val_loss: 0.4171 - val_acc: 0.7317\n",
      "Epoch 4/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.3869 - acc: 0.8649\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99329727,  0.02368513]), array([ 0.75084444,  0.544     ]), array([ 0.8552192 ,  0.04539386]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 944s - loss: 0.3865 - acc: 0.8653 - val_loss: 0.4040 - val_acc: 0.7486\n",
      "Epoch 5/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.2376 - acc: 0.9203\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.9927831 ,  0.02507283]), array([ 0.79175556,  0.482     ]), array([ 0.88094649,  0.04766614]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 942s - loss: 0.2382 - acc: 0.9198 - val_loss: 0.3937 - val_acc: 0.7884\n",
      "Epoch 6/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.1265 - acc: 0.9599\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99226578,  0.02653968]), array([ 0.82964444,  0.418     ]), array([ 0.90369743,  0.04991045]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 942s - loss: 0.1265 - acc: 0.9598 - val_loss: 0.3646 - val_acc: 0.8251\n",
      "Epoch 7/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.0774 - acc: 0.9756\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99213527,  0.02719239]), array([ 0.841,  0.4  ]), array([ 0.91033736,  0.05092298]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 942s - loss: 0.0773 - acc: 0.9757 - val_loss: 0.3698 - val_acc: 0.8362\n",
      "Epoch 8/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.0538 - acc: 0.9827\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99150056,  0.02747989]), array([ 0.87102222,  0.328     ]), array([ 0.92736478,  0.05071119]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 941s - loss: 0.0538 - acc: 0.9827 - val_loss: 0.3591 - val_acc: 0.8651\n",
      "Epoch 9/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.0357 - acc: 0.9874\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99186971,  0.02670666]), array([ 0.84855556,  0.374     ]), array([ 0.91463269,  0.04985337]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 948s - loss: 0.0359 - acc: 0.9874 - val_loss: 0.4631 - val_acc: 0.8433\n",
      "Epoch 10/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.0248 - acc: 0.9898\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99653039,  0.01559896]), array([ 0.38295556,  0.88      ]), array([ 0.55328849,  0.03065454]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 943s - loss: 0.0350 - acc: 0.9890 - val_loss: 4.2917 - val_acc: 0.3884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0742906dd0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_weights(initial_weights)\n",
    "print('Train...')\n",
    "metrics = Metrics(MOD_DIR + \"none\")\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          class_weight = {0. : 1, 1. : 3},\n",
    "validation_data=[x_test, y_test],\n",
    "         callbacks = [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 9937 samples, validate on 45500 samples\n",
      "Epoch 1/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.9607 - acc: 0.8491\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.9930811 ,  0.01718499]), array([ 0.60602222,  0.62      ]), array([ 0.75270835,  0.03344301]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 945s - loss: 0.9627 - acc: 0.8488 - val_loss: 0.5844 - val_acc: 0.6062\n",
      "Epoch 2/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.7907 - acc: 0.7393\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99490532,  0.0165952 ]), array([ 0.49037778,  0.774     ]), array([ 0.65695147,  0.0324937 ]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 945s - loss: 0.7915 - acc: 0.7391 - val_loss: 0.6384 - val_acc: 0.4935\n",
      "Epoch 3/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.6357 - acc: 0.7536\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99389617,  0.01970865]), array([ 0.64408889,  0.644     ]), array([ 0.78164019,  0.03824682]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 944s - loss: 0.6352 - acc: 0.7538 - val_loss: 0.5015 - val_acc: 0.6441\n",
      "Epoch 4/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.4644 - acc: 0.8275\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99511775,  0.02063024]), array([ 0.616,  0.728]), array([ 0.76095311,  0.04012346]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 944s - loss: 0.4660 - acc: 0.8267 - val_loss: 0.6128 - val_acc: 0.6172\n",
      "Epoch 5/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.2821 - acc: 0.9022\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99290431,  0.02324098]), array([ 0.76184444,  0.51      ]), array([ 0.86216175,  0.04445607]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 942s - loss: 0.2816 - acc: 0.9025 - val_loss: 0.5004 - val_acc: 0.7591\n",
      "Epoch 6/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.1547 - acc: 0.9465\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99284442,  0.02435177]), array([ 0.78008889,  0.494     ]), array([ 0.87370111,  0.04641548]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 942s - loss: 0.1549 - acc: 0.9466 - val_loss: 0.5489 - val_acc: 0.7769\n",
      "Epoch 7/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.0713 - acc: 0.9744\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99154624,  0.02537029]), array([ 0.85231111,  0.346     ]), array([ 0.91667165,  0.04727422]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 942s - loss: 0.0711 - acc: 0.9744 - val_loss: 0.5561 - val_acc: 0.8467\n",
      "Epoch 8/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.1350 - acc: 0.9715\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99177251,  0.02404633]), array([ 0.82773333,  0.382     ]), array([ 0.90235837,  0.04524458]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 943s - loss: 0.1347 - acc: 0.9714 - val_loss: 0.5531 - val_acc: 0.8228\n",
      "Epoch 9/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.0457 - acc: 0.9850\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99208652,  0.02635046]), array([ 0.83577778,  0.4       ]), array([ 0.90724882,  0.04944376]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 942s - loss: 0.0457 - acc: 0.9848 - val_loss: 0.6458 - val_acc: 0.8310\n",
      "Epoch 10/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.0170 - acc: 0.9918\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99225905,  0.02451203]), array([ 0.80897778,  0.432     ]), array([ 0.8912937 ,  0.04639175]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 943s - loss: 0.0170 - acc: 0.9918 - val_loss: 0.9163 - val_acc: 0.8048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f06df62de90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_weights(initial_weights)\n",
    "print('Train...')\n",
    "metrics = Metrics(MOD_DIR + \"none\")\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          class_weight = {0. : 1, 1. : 5},\n",
    "validation_data=[x_test, y_test],\n",
    "         callbacks = [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 9937 samples, validate on 45500 samples\n",
      "Epoch 1/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 1.2308 - acc: 0.3964\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99703628,  0.01318774]), array([ 0.2168,  0.942 ]), array([ 0.35615588,  0.02601132]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 945s - loss: 1.2318 - acc: 0.3959 - val_loss: 0.8779 - val_acc: 0.2248\n",
      "Epoch 2/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 1.0929 - acc: 0.6033\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99590902,  0.02871714]), array([ 0.72491111,  0.732     ]), array([ 0.83907144,  0.05526614]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 945s - loss: 1.0916 - acc: 0.6023 - val_loss: 0.5299 - val_acc: 0.7250\n",
      "Epoch 3/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.8402 - acc: 0.7212\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99853657,  0.02532064]), array([ 0.60651111,  0.92      ]), array([ 0.75464864,  0.04928483]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 944s - loss: 0.8413 - acc: 0.7214 - val_loss: 0.6298 - val_acc: 0.6100\n",
      "Epoch 4/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.5704 - acc: 0.8292\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99479426,  0.04138595]), array([ 0.84506667,  0.602     ]), array([ 0.91383806,  0.07744757]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 945s - loss: 0.5700 - acc: 0.8290 - val_loss: 0.3089 - val_acc: 0.8424\n",
      "Epoch 5/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.2474 - acc: 0.9329\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.9933545 ,  0.04721823]), array([ 0.89686667,  0.46      ]), array([ 0.94264793,  0.08564513]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 944s - loss: 0.2472 - acc: 0.9326 - val_loss: 0.2386 - val_acc: 0.8921\n",
      "Epoch 6/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.0771 - acc: 0.9803\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99296563,  0.0477808 ]), array([ 0.90655556,  0.422     ]), array([ 0.94779518,  0.08584215]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 945s - loss: 0.0770 - acc: 0.9803 - val_loss: 0.3106 - val_acc: 0.9012\n",
      "Epoch 7/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.0233 - acc: 0.9934\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99248031,  0.05291918]), array([ 0.92682222,  0.368     ]), array([ 0.95852821,  0.09253206]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 941s - loss: 0.0231 - acc: 0.9935 - val_loss: 0.3070 - val_acc: 0.9207\n",
      "Epoch 8/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.0090 - acc: 0.9981\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99237877,  0.05125285]), array([ 0.92595556,  0.36      ]), array([ 0.9580172 ,  0.08973081]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 938s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.3451 - val_acc: 0.9197\n",
      "Epoch 9/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 0.0030 - acc: 0.9995\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99260164,  0.04334433]), array([ 0.90337778,  0.394     ]), array([ 0.94589029,  0.07809713]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 942s - loss: 0.0030 - acc: 0.9995 - val_loss: 0.5073 - val_acc: 0.8978\n",
      "Epoch 10/10\n",
      "9856/9937 [============================>.] - ETA: 1s - loss: 9.1914e-04 - acc: 0.9998\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99246426,  0.04468085]), array([ 0.9102,  0.378 ]), array([ 0.94955373,  0.07991543]), array([45000,   500]))\n",
      "9937/9937 [==============================] - 942s - loss: 9.1487e-04 - acc: 0.9998 - val_loss: 0.4965 - val_acc: 0.9044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f06dfe870d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_weights(initial_weights)\n",
    "print('Train...')\n",
    "metrics = Metrics(MOD_DIR + \"none\")\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          class_weight = {0. : 1, 1. : 8},\n",
    "validation_data=[x_test, y_test],\n",
    "         callbacks = [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
