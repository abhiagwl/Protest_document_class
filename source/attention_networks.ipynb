{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "BASE_DIR = ''\n",
    "GLOVE_DIR = '/home/abhinav/data/GLOVE_DATA/glove.6B'\n",
    "TEXT_DATA_DIR = '/home/abhinav/data/full_text'\n",
    "THIRD_MOD_DIR = \"/home/abhinav/data/third_model/\"\n",
    "SECOND_MOD_DIR = \"/home/abhinav/data/second_model/\"\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NB_WORDS = 50000\n",
    "EMBEDDING_DIM = 200\n",
    "FOURTH_MOD_DIR = \"/home/abhinav/data/fourth_model/\"\n",
    "\n",
    "print('Loading data...')\n",
    "[x_train, y_train] = pd.read_pickle(FOURTH_MOD_DIR + \"train_data_10ratio\") \n",
    "\n",
    "[x_test, y_test] = pd.read_pickle(FOURTH_MOD_DIR + \"test_dataset\") \n",
    "\n",
    "[x_val, y_val ] = pd.read_pickle(FOURTH_MOD_DIR + \"validation_dataset\")\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D,merge, MaxPooling1D, Embedding,Merge,  Dropout\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers.merge import Add,Concatenate,Dot\n",
    "\n",
    "num_words = MAX_NB_WORDS\n",
    "\n",
    "embedding_matrix = pd.read_pickle(\"/home/abhinav/data/fourth_model/embedding_matrix_for_selected_words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import os\n",
    "\n",
    "def set_keras_backend(backend):\n",
    "\n",
    "    if K.backend() != backend:\n",
    "        os.environ['KERAS_BACKEND'] = backend\n",
    "        reload(K)\n",
    "        assert K.backend() == backend\n",
    "\n",
    "set_keras_backend(\"theano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Metrics(keras.callbacks.Callback):\n",
    "    def __init__(self,filepath):\n",
    "        self.filepath = filepath\n",
    "        self.best = -np.Inf\n",
    "    def on_epoch_end(self, epoch,batch, logs={}):\n",
    "        predict = self.model.predict(self.validation_data[0],batch_size = 512)\n",
    "        predict = prob_to_label(predict)\n",
    "        targ = self.validation_data[1]\n",
    "        self.f1s=f1(targ, predict)\n",
    "        \"\"\"if self.f1s > self.best:\n",
    "            self.best = self.f1s\n",
    "            print('Epoch %05d: improved f1 to %0.5f,'\n",
    "                                  ' saving model to %s'\n",
    "                                  % (epoch, self.best, self.filepath))\n",
    "            self.model.save(self.filepath,overwrite =True)\"\"\"\n",
    "        print (\"\\nWeighted F1 score found on Validation dataset : \" ,self.f1s)\n",
    "        return\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "def f1(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true = y_true, y_pred = y_pred)\n",
    "ndm = keras.optimizers.Nadam(lr = 0.001)    \n",
    "\n",
    "def prob_to_label(array):\n",
    "    for a in array:\n",
    "        if a[0] > a[1] :\n",
    "            a[0] = 1\n",
    "            a[1] = 0\n",
    "        elif a[0] < a[1]:\n",
    "            a[0] = 0\n",
    "            a[1] = 1\n",
    "        else:\n",
    "            ind = np.random.randint(2)\n",
    "            a[ind]= 1\n",
    "            a[int(1-ind)] = 0\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers\n",
    "from keras.layers import Bidirectional, LSTM, GRU,TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class AttLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.init = initializers.RandomNormal()\n",
    "        #self.input_spec = [InputSpec(ndim=3)]\n",
    "        super(AttLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape)==3\n",
    "        #self.W = self.init((input_shape[-1],1))\n",
    "        self.W = self.init((input_shape[-1],))\n",
    "        #self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        self.trainable_weights = [self.W]\n",
    "        super(AttLayer, self).build(input_shape)  # be sure you call this somewhere!\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        eij = K.tanh(K.dot(x, self.W))\n",
    "        \n",
    "        ai = K.exp(eij)\n",
    "        weights = ai/K.sum(ai, axis=1).dimshuffle(0,'x')\n",
    "        \n",
    "        weighted_input = x*weights.dimshuffle(0,1,'x')\n",
    "        return weighted_input.sum(axis=1)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "l_gru = Bidirectional(GRU(50, return_sequences=True))(embedded_sequences)\n",
    "l_att = AttLayer()(l_gru)\n",
    "preds = Dense(2, activation='softmax')(l_att)\n",
    "model = Model(sequence_input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SENTS  = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sentence_input)\n",
    "l_lstm = Bidirectional(LSTM(100))(embedded_sequences)\n",
    "sentEncoder = Model(sentence_input, l_lstm)\n",
    "\n",
    "review_input = Input(shape=(MAX_SENTS,MAX_SEQUENCE_LENGTH), dtype='int32')\n",
    "review_encoder = TimeDistributed(sentEncoder)(review_input)\n",
    "l_lstm_sent = Bidirectional(LSTM(100))(review_encoder)\n",
    "preds = Dense(2, activation='softmax')(l_lstm_sent)\n",
    "model = Model(review_input, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/topology.py:2248: UserWarning: Class `__main__.AttLayer` defines `get_output_shape_for` but does not override `compute_output_shape`. If this is a Keras 1 layer, please implement `compute_output_shape` to support Keras 2.\n",
      "  shapes = _to_list(layer.compute_output_shape(computed_tensors[0]._keras_shape))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer time_distributed_6: expected ndim=3, found ndim=4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-1e596349ac02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mreview_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentEncoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0ml_lstm_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_encoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0ml_dense_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_lstm_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0ml_att_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_dense_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_att_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0;31m# with the input_spec set at build time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    449\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer time_distributed_6: expected ndim=3, found ndim=4"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "l_lstm = Bidirectional(GRU(100, return_sequences=True))(embedded_sequences)\n",
    "l_dense = TimeDistributed(Dense(200))(l_lstm)\n",
    "l_att = AttLayer()(l_dense)\n",
    "sentEncoder = Model(sequence_input, l_att)\n",
    "\n",
    "review_input = Input(shape=(MAX_SENTS,MAX_SEQUENCE_LENGTH), dtype='int32')\n",
    "review_encoder = TimeDistributed(sentEncoder)(review_input)\n",
    "l_lstm_sent = Bidirectional(GRU(100, return_sequences=True))(review_encoder)\n",
    "\n",
    "l_dense_sent = TimeDistributed(Dense(200))(l_lstm_sent)\n",
    "l_att_sent = AttLayer()(l_dense_sent)\n",
    "preds = Dense(2, activation='softmax')(l_att_sent)\n",
    "model = Model(review_input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer flatten_2: expected min_ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-d34831f8da24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    474\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    475\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    465\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected min_ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    468\u001b[0m             \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer flatten_2: expected min_ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(num_words, EMBEDDING_DIM, weights=[embedding_matrix], \n",
    "                    input_length=MAX_SEQUENCE_LENGTH,trainable = False))\n",
    "model.add(Bidirectional(LSTM(50,return_sequences=True)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(AttLayer())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 15, 1000)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 15, 200)           10240800  \n",
      "_________________________________________________________________\n",
      "bidirectional_20 (Bidirectio (None, 200)               240800    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 10,482,002\n",
      "Trainable params: 10,482,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=ndm,\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_15 to have 3 dimensions, but got array with shape (13150, 1000)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-0f28b22362ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0.\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m          callbacks = [metrics])\n\u001b[0m",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1433\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1436\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1309\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1311\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1312\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1313\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    125\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_15 to have 3 dimensions, but got array with shape (13150, 1000)"
     ]
    }
   ],
   "source": [
    "#model.set_weights(initial_weights)\n",
    "metrics = Metrics(FOURTH_MOD_DIR + \"none\")\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          class_weight = {0. : 1, 1. : 12},\n",
    "validation_data=[x_test, y_test],\n",
    "         callbacks = [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13150 samples, validate on 15165 samples\n",
      "Epoch 1/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 1.0621 - acc: 0.6901\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.9995951 ,  0.03045781]), array([ 0.65833333,  0.97575758]), array([ 0.7938422 ,  0.05907173]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 325s - loss: 1.0628 - acc: 0.6911 - val_loss: 0.6460 - val_acc: 0.6618\n",
      "Epoch 2/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.6110 - acc: 0.8635\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99835858,  0.08115778]), array([ 0.89206667,  0.86666667]), array([ 0.94222441,  0.14841723]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 327s - loss: 0.6098 - acc: 0.8636 - val_loss: 0.2627 - val_acc: 0.8918\n",
      "Epoch 3/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.4403 - acc: 0.8929\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99821681,  0.08264947]), array([ 0.89566667,  0.85454545]), array([ 0.94416529,  0.15072154]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 336s - loss: 0.4397 - acc: 0.8928 - val_loss: 0.2375 - val_acc: 0.8952\n",
      "Epoch 4/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.3110 - acc: 0.9238\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99761956,  0.10138249]), array([ 0.922,  0.8  ]), array([ 0.95832034,  0.1799591 ]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 340s - loss: 0.3112 - acc: 0.9240 - val_loss: 0.1841 - val_acc: 0.9207\n",
      "Epoch 5/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.2235 - acc: 0.9468\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99734367,  0.10355987]), array([ 0.92613333,  0.77575758]), array([ 0.96042034,  0.18272662]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 336s - loss: 0.2227 - acc: 0.9470 - val_loss: 0.2077 - val_acc: 0.9245\n",
      "Epoch 6/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.1781 - acc: 0.9602\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99687567,  0.11182994]), array([ 0.93593333,  0.73333333]), array([ 0.96544373,  0.19406576]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 327s - loss: 0.1780 - acc: 0.9601 - val_loss: 0.1863 - val_acc: 0.9337\n",
      "Epoch 7/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.1365 - acc: 0.9692\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99551693,  0.15015015]), array([ 0.96226667,  0.60606061]), array([ 0.97860944,  0.24067389]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 341s - loss: 0.1358 - acc: 0.9694 - val_loss: 0.1299 - val_acc: 0.9584\n",
      "Epoch 8/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.0830 - acc: 0.9829\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99567462,  0.12394705]), array([ 0.95146667,  0.62424242]), array([ 0.97306879,  0.20682731]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 320s - loss: 0.0828 - acc: 0.9830 - val_loss: 0.1781 - val_acc: 0.9479\n",
      "Epoch 9/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.0831 - acc: 0.9831\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99568786,  0.13087675]), array([ 0.9544    ,  0.62424242]), array([ 0.97460685,  0.21638655]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 327s - loss: 0.0829 - acc: 0.9832 - val_loss: 0.1722 - val_acc: 0.9508\n",
      "Epoch 10/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.0566 - acc: 0.9889\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99533491,  0.12204234]), array([ 0.953     ,  0.59393939]), array([ 0.97370751,  0.20247934]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 339s - loss: 0.0562 - acc: 0.9890 - val_loss: 0.1910 - val_acc: 0.9491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd5c3cf350>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_weights(initial_weights)\n",
    "metrics = Metrics(FOURTH_MOD_DIR + \"none\")\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          class_weight = {0. : 1, 1. : 10},\n",
    "validation_data=[x_test, y_test],\n",
    "         callbacks = [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13150 samples, validate on 15165 samples\n",
      "Epoch 1/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 1.0244 - acc: 0.7000\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99831275,  0.06726246]), array([ 0.8678    ,  0.86666667]), array([ 0.92849246,  0.12483632]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 368s - loss: 1.0207 - acc: 0.7016 - val_loss: 0.3410 - val_acc: 0.8678\n",
      "Epoch 2/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.6201 - acc: 0.8545\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99915154,  0.04587156]), array([ 0.78506667,  0.93939394]), array([ 0.87926529,  0.08747178]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 325s - loss: 0.6192 - acc: 0.8541 - val_loss: 0.4175 - val_acc: 0.7867\n",
      "Epoch 3/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.4360 - acc: 0.8955\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99868523,  0.06621924]), array([ 0.86086667,  0.8969697 ]), array([ 0.92466881,  0.12333333]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 318s - loss: 0.4358 - acc: 0.8959 - val_loss: 0.3216 - val_acc: 0.8613\n",
      "Epoch 4/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.2883 - acc: 0.9307\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99846896,  0.06898192]), array([ 0.86953333,  0.87878788]), array([ 0.92955137,  0.12792236]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 318s - loss: 0.2901 - acc: 0.9307 - val_loss: 0.3088 - val_acc: 0.8696\n",
      "Epoch 5/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.2038 - acc: 0.9549\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99566891,  0.16478191]), array([ 0.96553333,  0.61818182]), array([ 0.98036959,  0.26020408]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 317s - loss: 0.2032 - acc: 0.9548 - val_loss: 0.1222 - val_acc: 0.9618\n",
      "Epoch 6/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.1245 - acc: 0.9731\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99563863,  0.14166667]), array([ 0.9588    ,  0.61818182]), array([ 0.97687213,  0.23050847]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 318s - loss: 0.1252 - acc: 0.9732 - val_loss: 0.1451 - val_acc: 0.9551\n",
      "Epoch 7/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.0918 - acc: 0.9801\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99555956,  0.13430851]), array([ 0.9566    ,  0.61212121]), array([ 0.97569102,  0.22028353]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 317s - loss: 0.0918 - acc: 0.9800 - val_loss: 0.1614 - val_acc: 0.9529\n",
      "Epoch 8/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.0609 - acc: 0.9874\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99608775,  0.12808461]), array([ 0.95053333,  0.66060606]), array([ 0.97277751,  0.21456693]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 317s - loss: 0.0612 - acc: 0.9872 - val_loss: 0.1963 - val_acc: 0.9474\n",
      "Epoch 9/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.0535 - acc: 0.9893\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99520318,  0.16608392]), array([ 0.9682    ,  0.57575758]), array([ 0.9815159,  0.2578019]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 317s - loss: 0.0538 - acc: 0.9891 - val_loss: 0.1519 - val_acc: 0.9639\n",
      "Epoch 10/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.0351 - acc: 0.9923\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99536204,  0.13630042]), array([ 0.9586    ,  0.59393939]), array([ 0.9766352 ,  0.22171946]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 318s - loss: 0.0354 - acc: 0.9922 - val_loss: 0.1839 - val_acc: 0.9546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd12be3810>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_weights(initial_weights)\n",
    "metrics = Metrics(FOURTH_MOD_DIR + \"none\")\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          class_weight = {0. : 1, 1. : 12},\n",
    "validation_data=[x_test, y_test],\n",
    "         callbacks = [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13150 samples, validate on 15165 samples\n",
      "Epoch 1/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 1.0880 - acc: 0.6324\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99876594,  0.04983389]), array([ 0.80933333,  0.90909091]), array([ 0.89412631,  0.09448819]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 317s - loss: 1.0859 - acc: 0.6333 - val_loss: 0.4298 - val_acc: 0.8104\n",
      "Epoch 2/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.7124 - acc: 0.8229\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99730674,  0.08969867]), array([ 0.9134    ,  0.77575758]), array([ 0.95351103,  0.16080402]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 316s - loss: 0.7101 - acc: 0.8236 - val_loss: 0.2316 - val_acc: 0.9119\n",
      "Epoch 3/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.5304 - acc: 0.8696\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99853112,  0.06547085]), array([ 0.86106667,  0.88484848]), array([ 0.9247181 ,  0.12192067]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 317s - loss: 0.5298 - acc: 0.8693 - val_loss: 0.3117 - val_acc: 0.8613\n",
      "Epoch 4/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.3730 - acc: 0.9151\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99839841,  0.07014126]), array([ 0.87273333,  0.87272727]), array([ 0.93134604,  0.12984671]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 333s - loss: 0.3730 - acc: 0.9154 - val_loss: 0.3290 - val_acc: 0.8727\n",
      "Epoch 5/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.2932 - acc: 0.9336\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99673156,  0.10907424]), array([ 0.9352    ,  0.72121212]), array([ 0.9649859 ,  0.18949045]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 327s - loss: 0.2924 - acc: 0.9338 - val_loss: 0.1815 - val_acc: 0.9329\n",
      "Epoch 6/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.2505 - acc: 0.9443\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99695748,  0.11821705]), array([ 0.93933333,  0.73939394]), array([ 0.96728796,  0.20384294]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 321s - loss: 0.2494 - acc: 0.9447 - val_loss: 0.1951 - val_acc: 0.9372\n",
      "Epoch 7/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.1734 - acc: 0.9652\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99660465,  0.11381323]), array([ 0.93926667,  0.70909091]), array([ 0.96708652,  0.19614417]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 317s - loss: 0.1727 - acc: 0.9652 - val_loss: 0.1854 - val_acc: 0.9368\n",
      "Epoch 8/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.1485 - acc: 0.9714\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99659018,  0.10753676]), array([ 0.93526667,  0.70909091]), array([ 0.96495512,  0.1867518 ]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 319s - loss: 0.1485 - acc: 0.9714 - val_loss: 0.1988 - val_acc: 0.9328\n",
      "Epoch 9/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.0898 - acc: 0.9823\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99654272,  0.11693548]), array([ 0.9416   ,  0.7030303]), array([ 0.9682926 ,  0.20051858]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 320s - loss: 0.0895 - acc: 0.9824 - val_loss: 0.1988 - val_acc: 0.9390\n",
      "Epoch 10/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.0823 - acc: 0.9853\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99556049,  0.13484646]), array([ 0.9568    ,  0.61212121]), array([ 0.97579549,  0.22100656]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 321s - loss: 0.0818 - acc: 0.9854 - val_loss: 0.1670 - val_acc: 0.9530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd12ba46d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_weights(initial_weights)\n",
    "metrics = Metrics(FOURTH_MOD_DIR + \"none\")\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          class_weight = {0. : 1, 1. : 15},\n",
    "validation_data=[x_test, y_test],\n",
    "         callbacks = [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13150 samples, validate on 15165 samples\n",
      "Epoch 1/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 1.3914 - acc: 0.3807\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.999571  ,  0.02756377]), array([ 0.62133333,  0.97575758]), array([ 0.76632133,  0.05361305]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 322s - loss: 1.3917 - acc: 0.3814 - val_loss: 0.8202 - val_acc: 0.6252\n",
      "Epoch 2/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.8743 - acc: 0.7926\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99938747,  0.0422799 ]), array([ 0.7614    ,  0.95757576]), array([ 0.86431058,  0.08098411]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 321s - loss: 0.8744 - acc: 0.7924 - val_loss: 0.5052 - val_acc: 0.7635\n",
      "Epoch 3/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.6378 - acc: 0.8548\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99919692,  0.05713233]), array([ 0.82946667,  0.93939394]), array([ 0.9064549 ,  0.10771369]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 321s - loss: 0.6372 - acc: 0.8544 - val_loss: 0.4283 - val_acc: 0.8307\n",
      "Epoch 4/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.4864 - acc: 0.8871\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99898334,  0.06391926]), array([ 0.8516    ,  0.92121212]), array([ 0.91942275,  0.11954385]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 321s - loss: 0.4878 - acc: 0.8871 - val_loss: 0.4079 - val_acc: 0.8524\n",
      "Epoch 5/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.3112 - acc: 0.9318\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99856654,  0.05636503]), array([ 0.83593333,  0.89090909]), array([ 0.91004101,  0.10602236]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 321s - loss: 0.3129 - acc: 0.9319 - val_loss: 0.4548 - val_acc: 0.8365\n",
      "Epoch 6/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.2492 - acc: 0.9452\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99708351,  0.11201445]), array([ 0.93446667,  0.75151515]), array([ 0.96476013,  0.19496855]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 322s - loss: 0.2494 - acc: 0.9452 - val_loss: 0.1987 - val_acc: 0.9325\n",
      "Epoch 7/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.1744 - acc: 0.9642\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99747384,  0.09923664]), array([ 0.92133333,  0.78787879]), array([ 0.95789291,  0.17627119]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 321s - loss: 0.1738 - acc: 0.9643 - val_loss: 0.2474 - val_acc: 0.9199\n",
      "Epoch 8/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.1225 - acc: 0.9743\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99754122,  0.09798055]), array([ 0.9196    ,  0.79393939]), array([ 0.95698626,  0.17443409]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 325s - loss: 0.1228 - acc: 0.9743 - val_loss: 0.2892 - val_acc: 0.9182\n",
      "Epoch 9/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.0921 - acc: 0.9813\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99589051,  0.13118812]), array([ 0.9532    ,  0.64242424]), array([ 0.97407773,  0.21788284]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 322s - loss: 0.0918 - acc: 0.9814 - val_loss: 0.1860 - val_acc: 0.9498\n",
      "Epoch 10/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.0611 - acc: 0.9881\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99655488,  0.12314225]), array([ 0.94493333,  0.7030303 ]), array([ 0.97005783,  0.20957543]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 318s - loss: 0.0611 - acc: 0.9881 - val_loss: 0.2182 - val_acc: 0.9423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd0d828510>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_weights(initial_weights)\n",
    "metrics = Metrics(FOURTH_MOD_DIR + \"none\")\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          class_weight = {0. : 1, 1. : 20},\n",
    "validation_data=[x_test, y_test],\n",
    "         callbacks = [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13150 samples, validate on 15165 samples\n",
      "Epoch 1/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 1.5838 - acc: 0.4036\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99924573,  0.0482524 ]), array([ 0.79486667,  0.94545455]), array([ 0.88541512,  0.09181872]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 320s - loss: 1.5791 - acc: 0.4064 - val_loss: 0.5419 - val_acc: 0.7965\n",
      "Epoch 2/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.9673 - acc: 0.7640\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99930957,  0.04387926]), array([ 0.77193333,  0.95151515]), array([ 0.87102719,  0.08388993]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 320s - loss: 0.9671 - acc: 0.7647 - val_loss: 0.5668 - val_acc: 0.7739\n",
      "Epoch 3/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.6484 - acc: 0.8555\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99766679,  0.09172414]), array([ 0.9122    ,  0.80606061]), array([ 0.95302107,  0.16470588]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 318s - loss: 0.6473 - acc: 0.8557 - val_loss: 0.2281 - val_acc: 0.9110\n",
      "Epoch 4/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.4429 - acc: 0.9024\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99674981,  0.11758893]), array([ 0.94046667,  0.72121212]), array([ 0.96779062,  0.20220901]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 318s - loss: 0.4437 - acc: 0.9021 - val_loss: 0.1719 - val_acc: 0.9381\n",
      "Epoch 5/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.3049 - acc: 0.9386\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99714081,  0.10638298]), array([ 0.93      ,  0.75757576]), array([ 0.96240083,  0.18656716]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 319s - loss: 0.3056 - acc: 0.9386 - val_loss: 0.2315 - val_acc: 0.9281\n",
      "Epoch 6/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.2267 - acc: 0.9536\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99573385,  0.16297468]), array([ 0.96473333,  0.62424242]), array([ 0.97998849,  0.25846926]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 319s - loss: 0.2266 - acc: 0.9535 - val_loss: 0.1439 - val_acc: 0.9610\n",
      "Epoch 7/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.1711 - acc: 0.9682\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99653514,  0.11339198]), array([ 0.93953333,  0.7030303 ]), array([ 0.96719511,  0.1952862 ]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 319s - loss: 0.1707 - acc: 0.9684 - val_loss: 0.2274 - val_acc: 0.9370\n",
      "Epoch 8/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.1211 - acc: 0.9766\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99684362,  0.09877551]), array([ 0.9264    ,  0.73333333]), array([ 0.96033172,  0.17410072]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 318s - loss: 0.1227 - acc: 0.9767 - val_loss: 0.2985 - val_acc: 0.9243\n",
      "Epoch 9/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.1146 - acc: 0.9786\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99592063,  0.15099715]), array([ 0.96026667,  0.64242424]), array([ 0.97776873,  0.24452134]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 320s - loss: 0.1154 - acc: 0.9785 - val_loss: 0.1845 - val_acc: 0.9568\n",
      "Epoch 10/10\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.0664 - acc: 0.9881\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99529867,  0.13837375]), array([ 0.95973333,  0.58787879]), array([ 0.97719251,  0.22401848]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 319s - loss: 0.0662 - acc: 0.9880 - val_loss: 0.1975 - val_acc: 0.9557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd5c44b390>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_weights(initial_weights)\n",
    "metrics = Metrics(FOURTH_MOD_DIR + \"none\")\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          class_weight = {0. : 1, 1. : 30},\n",
    "validation_data=[x_test, y_test],\n",
    "         callbacks = [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.set_weights(initial_weights)\n",
    "metrics = Metrics(FOURTH_MOD_DIR + \"none\")\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          class_weight = {0. : 1, 1. : 50},\n",
    "validation_data=[x_test, y_test],\n",
    "         callbacks = [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.set_weights(initial_weights)\n",
    "metrics = Metrics(FOURTH_MOD_DIR + \"none\")\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          class_weight = {0. : 1, 1. : 75},\n",
    "validation_data=[x_test, y_test],\n",
    "         callbacks = [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.set_weights(initial_weights)\n",
    "metrics = Metrics(FOURTH_MOD_DIR + \"none\")\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          class_weight = {0. : 1, 1. : 100},\n",
    "validation_data=[x_test, y_test],\n",
    "         callbacks = [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.set_weights(initial_weights)\n",
    "metrics = Metrics(FOURTH_MOD_DIR + \"none\")\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          class_weight = {0. : 1, 1. : 125},\n",
    "validation_data=[x_test, y_test],\n",
    "         callbacks = [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13150 samples, validate on 15165 samples\n",
      "Epoch 1/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 2.7308 - acc: 0.1568\n",
      "Weighted F1 score found on Validation dataset :  (array([ 1.        ,  0.01704545]), array([ 0.36566667,  1.        ]), array([ 0.53551379,  0.03351955]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 321s - loss: 2.7281 - acc: 0.1587 - val_loss: 1.2697 - val_acc: 0.3726\n",
      "Epoch 2/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 1.8886 - acc: 0.5123\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99960684,  0.03225806]), array([ 0.678     ,  0.97575758]), array([ 0.80797648,  0.06245151]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 319s - loss: 1.8832 - acc: 0.5138 - val_loss: 0.8559 - val_acc: 0.6812\n",
      "Epoch 3/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 1.3161 - acc: 0.7084\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.9993245 ,  0.04726069]), array([ 0.789     ,  0.95151515]), array([ 0.88179414,  0.09004875]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 318s - loss: 1.3132 - acc: 0.7085 - val_loss: 0.6312 - val_acc: 0.7908\n",
      "Epoch 4/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.9276 - acc: 0.8065\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99943829,  0.05845357]), array([ 0.83033333,  0.95757576]), array([ 0.90707159,  0.11018131]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 325s - loss: 0.9264 - acc: 0.8066 - val_loss: 0.5470 - val_acc: 0.8317\n",
      "Epoch 5/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.6169 - acc: 0.8817"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-781b98609c02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0.\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m          callbacks = [metrics])\n\u001b[0m",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1174\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m                             \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d4c35e314950>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob_to_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtarg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1592\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1594\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1216\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.set_weights(initial_weights)\n",
    "metrics = Metrics(FOURTH_MOD_DIR + \"none\")\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          class_weight = {0. : 1, 1. : 150},\n",
    "validation_data=[x_test, y_test],\n",
    "         callbacks = [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13150 samples, validate on 15165 samples\n",
      "Epoch 1/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 3.3969 - acc: 0.0895\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.        ,  0.01088032]), array([ 0.,  1.]), array([ 0.        ,  0.02152642]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 328s - loss: 3.3978 - acc: 0.0898 - val_loss: 2.6060 - val_acc: 0.0109\n",
      "Epoch 2/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 1.9941 - acc: 0.3591\n",
      "Weighted F1 score found on Validation dataset :  (array([ 1.        ,  0.01807427]), array([ 0.4024,  1.    ]), array([ 0.57387336,  0.03550678]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 331s - loss: 1.9972 - acc: 0.3592 - val_loss: 1.7261 - val_acc: 0.4089\n",
      "Epoch 3/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 1.2913 - acc: 0.7218\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.9995438 ,  0.02516805]), array([ 0.58426667,  0.97575758]), array([ 0.73746213,  0.04907041]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 321s - loss: 1.2935 - acc: 0.7212 - val_loss: 1.5518 - val_acc: 0.5885\n",
      "Epoch 4/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 1.0179 - acc: 0.7963\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99884345,  0.04934641]), array([ 0.80606667,  0.91515152]), array([ 0.89216012,  0.09364341]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 319s - loss: 1.0172 - acc: 0.7960 - val_loss: 0.6714 - val_acc: 0.8073\n",
      "Epoch 5/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.6840 - acc: 0.8639\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99835848,  0.06070826]), array([ 0.85146667,  0.87272727]), array([ 0.91908034,  0.11351991]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 322s - loss: 0.6846 - acc: 0.8634 - val_loss: 0.5355 - val_acc: 0.8517\n",
      "Epoch 6/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.5035 - acc: 0.9076\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99780814,  0.09133965]), array([ 0.91046667,  0.81818182]), array([ 0.9521386 ,  0.16433354]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 317s - loss: 0.5026 - acc: 0.9078 - val_loss: 0.3583 - val_acc: 0.9095\n",
      "Epoch 7/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.5197 - acc: 0.9123\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99799331,  0.08070175]), array([ 0.8952    ,  0.83636364]), array([ 0.94380601,  0.1472    ]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 317s - loss: 0.5188 - acc: 0.9125 - val_loss: 0.3326 - val_acc: 0.8946\n",
      "Epoch 8/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.3803 - acc: 0.9308\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99752943,  0.09337135]), array([ 0.9152    ,  0.79393939]), array([ 0.95459287,  0.16709184]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 317s - loss: 0.3799 - acc: 0.9310 - val_loss: 0.3999 - val_acc: 0.9139\n",
      "Epoch 9/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.2258 - acc: 0.9622\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99692835,  0.10463122]), array([ 0.9304    ,  0.73939394]), array([ 0.96251595,  0.18332081]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 325s - loss: 0.2254 - acc: 0.9623 - val_loss: 0.3364 - val_acc: 0.9283\n",
      "Epoch 10/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.2181 - acc: 0.9596\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99730399,  0.0888272 ]), array([ 0.91246667,  0.77575758]), array([ 0.95300097,  0.15940224]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 328s - loss: 0.2182 - acc: 0.9598 - val_loss: 0.4558 - val_acc: 0.9110\n",
      "Epoch 11/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.2860 - acc: 0.9426\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.9971902 ,  0.09805447]), array([ 0.92273333,  0.76363636]), array([ 0.95851801,  0.1737931 ]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 325s - loss: 0.2843 - acc: 0.9428 - val_loss: 0.3549 - val_acc: 0.9210\n",
      "Epoch 12/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.1620 - acc: 0.9720\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99727701,  0.08116677]), array([ 0.9034    ,  0.77575758]), array([ 0.94802015,  0.14695752]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 333s - loss: 0.1611 - acc: 0.9720 - val_loss: 0.4991 - val_acc: 0.9020\n",
      "Epoch 13/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.1213 - acc: 0.9803\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99652901,  0.11068702]), array([ 0.93786667,  0.7030303 ]), array([ 0.96630834,  0.19126134]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 326s - loss: 0.1206 - acc: 0.9803 - val_loss: 0.3516 - val_acc: 0.9353\n",
      "Epoch 14/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.0819 - acc: 0.9877\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99615814,  0.12956419]), array([ 0.95073333,  0.66666667]), array([ 0.97291581,  0.21696252]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 322s - loss: 0.0815 - acc: 0.9878 - val_loss: 0.3040 - val_acc: 0.9476\n",
      "Epoch 15/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.0604 - acc: 0.9903\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99593838,  0.12090395]), array([ 0.94813333,  0.64848485]), array([ 0.97144809,  0.20380952]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 326s - loss: 0.0599 - acc: 0.9903 - val_loss: 0.3214 - val_acc: 0.9449\n",
      "Epoch 16/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.2507 - acc: 0.9562\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99664238,  0.10111397]), array([ 0.93006667,  0.71515152]), array([ 0.96220429,  0.17717718]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 322s - loss: 0.2492 - acc: 0.9563 - val_loss: 0.3495 - val_acc: 0.9277\n",
      "Epoch 17/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.0994 - acc: 0.9825\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99665338,  0.10526316]), array([ 0.93313333,  0.71515152]), array([ 0.96384795,  0.18351477]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 323s - loss: 0.0989 - acc: 0.9825 - val_loss: 0.3644 - val_acc: 0.9308\n",
      "Epoch 18/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.1729 - acc: 0.9806\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99933206,  0.03372465]), array([ 0.6982    ,  0.95757576]), array([ 0.82205651,  0.06515464]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 324s - loss: 0.1793 - acc: 0.9791 - val_loss: 1.8906 - val_acc: 0.7010\n",
      "Epoch 19/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.0897 - acc: 0.9827\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99562363,  0.10320641]), array([ 0.94033333,  0.62424242]), array([ 0.96718895,  0.17712812]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 321s - loss: 0.0892 - acc: 0.9828 - val_loss: 0.3665 - val_acc: 0.9369\n",
      "Epoch 20/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 0.1796 - acc: 0.9711\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.99546453,  0.09582543]), array([ 0.93646667,  0.61212121]), array([ 0.96506475,  0.1657096 ]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 321s - loss: 0.1784 - acc: 0.9713 - val_loss: 0.3280 - val_acc: 0.9329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd15cf61d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_weights(initial_weights)\n",
    "metrics = Metrics(FOURTH_MOD_DIR + \"none\")\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          class_weight = {0. : 1, 1. : 200},\n",
    "validation_data=[x_test, y_test],\n",
    "         callbacks = [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.set_weights(initial_weights)\n",
    "metrics = Metrics(FOURTH_MOD_DIR + \"none\")\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          class_weight = {0. : 1, 1. : 500},\n",
    "validation_data=[x_test, y_test],\n",
    "         callbacks = [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13150 samples, validate on 15165 samples\n",
      "Epoch 1/20\n",
      "13056/13150 [============================>.] - ETA: 1s - loss: 8.1149 - acc: 0.0897\n",
      "Weighted F1 score found on Validation dataset :  (array([ 0.        ,  0.01088032]), array([ 0.,  1.]), array([ 0.        ,  0.02152642]), array([15000,   165]))\n",
      "13150/13150 [==============================] - 325s - loss: 8.0891 - acc: 0.0895 - val_loss: 3.4302 - val_acc: 0.0109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/20\n",
      " 7168/13150 [===============>..............] - ETA: 86s - loss: 3.4647 - acc: 0.0871"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9bde2c0656f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0.\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m          callbacks = [metrics])\n\u001b[0m",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/miniconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.set_weights(initial_weights)\n",
    "metrics = Metrics(FOURTH_MOD_DIR + \"none\")\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          class_weight = {0. : 1, 1. : 1000},\n",
    "validation_data=[x_test, y_test],\n",
    "         callbacks = [metrics])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
